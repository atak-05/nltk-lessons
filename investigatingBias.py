import pickle
import nltk
import random
from nltk.corpus import movie_reviews
from nltk.classify.scikitlearn import SklearnClassifier
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.linear_model import LogisticRegression, SGDClassifier
from  sklearn.svm import NuSVC, SVC, LinearSVC
from nltk.classify import ClassifierI
from statistics import mode



"""
â¡â¢â¢â¢The expression "combining algorithms with a vote" refers to the process of using more than one algorithm in a forecasting or decision-making process and combining the results of these algorithms using the voting mechanism.
This method is frequently used in the fields of machine learning and artificial intelligence, and it provides more accurate results by analyzing data from different perspectives of multiple algorithms.
â¡
"""

class VoteClassifier(ClassifierI):
    def __init__(self,*classifiers):
        self._classifiers = classifiers
        
    def classify(self, features):
        votes = []
        for c in self._classifiers:
            v = c.classify(features)
            votes.append(v)
        return mode(votes)
    def confidence(self, features):
        votes = []
        for c in self._classifiers:
            v = c.classify(features)
            votes.append(v)
        choice_votes = votes.count(mode(votes))
        conf = choice_votes / len((votes))
        return conf
                


"""
â¡â¢â¢â¢â€‹â€Œâ€â€ŒNaive Bayes â€‹sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, makine Ã¶ÄŸrenmesinde sÄ±nÄ±flandÄ±rma problemlerini Ã§Ã¶zmek iÃ§in kullanÄ±lan bir algoritmadÄ±r. 
Bu algoritma, verileri istatistiksel bir yÃ¶ntemle sÄ±nÄ±flandÄ±rÄ±r. Ã–zellikle doÄŸal dil iÅŸlemede, spam filtreleme, duygu analizi gibi sÄ±nÄ±flandÄ±rma problemlerinde sÄ±klÄ±kla kullanÄ±lmaktadÄ±r.
Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, Bayes teoremi temel alÄ±narak oluÅŸturulur. 
Bayes teoremi, koÅŸullu olasÄ±lÄ±k hesaplamalarÄ±nda kullanÄ±lan bir matematiksel formÃ¼ldÃ¼r. Naive Bayes algoritmasÄ± ise bu teoreme dayalÄ± bir makine Ã¶ÄŸrenmesi algoritmasÄ±dÄ±r.
Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, Ã¶ÄŸrenme aÅŸamasÄ±nda eÄŸitim verilerini kullanarak her Ã¶zelliÄŸin sÄ±nÄ±fa ait olasÄ±lÄ±klarÄ±nÄ± hesaplar. 
SÄ±nÄ±flandÄ±rma yaparken, test verilerinin sÄ±nÄ±fÄ±na ait olasÄ±lÄ±klarÄ± hesaplar ve en yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±fÄ± seÃ§er.
Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, Ã¶zellikle kÃ¼Ã§Ã¼k boyutlu veri setlerinde etkili sonuÃ§lar verir ve hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r. Ancak, "naive" yani "saf" olarak adlandÄ±rÄ±lmasÄ±nÄ±n nedeni, modelin Ã¶zellikler arasÄ±ndaki baÄŸÄ±mlÄ±lÄ±klarÄ± gÃ¶z ardÄ± etmesidir. Bu nedenle, baÄŸÄ±msÄ±z olmayan Ã¶zelliklere sahip veri setleri iÃ§in daha az uygun olabilir.
"""





documents =[(list(movie_reviews.words(fileids=fileid)), category)
            for category in movie_reviews.categories()
            for fileid in movie_reviews.fileids(category) 
            ]
# random.shuffle(documents)



all_words = []
for w in movie_reviews.words():
    all_words.append(w.lower())
all_words = nltk.FreqDist(all_words)

word_features = list(all_words.keys())[:3000]

def find_features(document):
    words = set(document)
    features = {}
    for w in word_features:
        features[w] = (w in words)
    return features

# print(find_features(movie_reviews.words('neg/cv000_29416.txt')))

featuresets =  [ (find_features(rev),category)for (rev,category) in documents]

""" 
â¡â¢â¢â¡â¢â¢â¢training_set, ilk 1900 belgeyi iÃ§eren bir Ã¶zellik-kategori Ã§iftleri listesidir
ve testing_set, geri kalan belgeleri iÃ§eren bir liste.
SÄ±nÄ±flandÄ±rÄ±cÄ±, nltk.NaiveBayesClassifier.train() yÃ¶ntemi kullanÄ±larak eÄŸitilir ve doÄŸruluÄŸu test edilir. 
AyrÄ±ca, show_most_informative_features() yÃ¶ntemi kullanÄ±larak enformatik Ã¶zellikler yazdÄ±rÄ±lÄ±r.â¡
"""
#Positive data example:
training_set = featuresets[:1900]
testing_set = featuresets[1900:]


#Negative data example:
training_set = featuresets[100:]
testing_set = featuresets[:100]

# classifier = nltk.NaiveBayesClassifier.train(training_set)


"""
â€‹â€Œâ€â¡â¢â¢â¢â€Œnaivebayes.pickle â€‹dosyasÄ±nÄ± okuyor ve iÃ§indeki eÄŸitilmiÅŸ sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± classifier deÄŸiÅŸkenine yÃ¼klÃ¼yor. 
ArdÄ±ndan, bu sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± test veri seti (testing_set) Ã¼zerinde deÄŸerlendiriyor ve doÄŸruluk oranÄ±nÄ± ekrana yazdÄ±rÄ±yor.
Son olarak, sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n en bilgilendirici Ã¶zelliklerini ekrana yazdÄ±rÄ±yor.

Bu kod, daha Ã¶nce eÄŸitilmiÅŸ bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n yÃ¼klenmesini gÃ¶steriyor. 
Bu ÅŸekilde, sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± yeniden eÄŸitmeden Ã¶nce kaydedilen eÄŸitilmiÅŸ bir modele eriÅŸebilirsiniz.
pickle modÃ¼lÃ¼, Python nesnelerini serileÅŸtirmek ve deserialize etmek iÃ§in kullanÄ±lÄ±r.
Bu Ã¶rnekte, pickle kullanÄ±larak eÄŸitilmiÅŸ sÄ±nÄ±flandÄ±rÄ±cÄ± bir dosyaya kaydedilmiÅŸ ve daha sonra bu dosyadan tekrar yÃ¼klenebilmiÅŸtir.â¡
"""
classifier_f =open("naivebayes.pickle","rb")
classifier = pickle.load(classifier_f)
classifier_f.close()
print ("Original Naive Bayes Algo accuracy percent :  ",(nltk.classify.accuracy(classifier,testing_set))*100 )
classifier.show_most_informative_features(15)
print("--------------MNB_classifie------------------")
"""
â¡â¢â¢â¢Bu kod, Scikit-learn kÃ¼tÃ¼phanesininâ€‹â€Œâ€â€Œ ğ— ğ˜‚ğ—¹ğ˜ğ—¶ğ—»ğ—¼ğ—ºğ—¶ğ—®ğ—¹ ğ—¡ğ—®ğ—¶ğ˜ƒğ—² ğ—•ğ—®ğ˜†ğ—²ğ˜€â€‹ sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± kullanarak bir sÄ±nÄ±flandÄ±rÄ±cÄ± eÄŸitmeyi ve test etmeyi gÃ¶sterir.
Ä°lk olarak, SklearnClassifier sÄ±nÄ±fÄ± kullanÄ±larak, NLTK sÄ±nÄ±flandÄ±rma modeli Scikit-learn sÄ±nÄ±flandÄ±rma modeline dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. 
Daha sonra, MultinomialNB() sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± kullanÄ±larak eÄŸitim setindeki belgelerin sÄ±nÄ±flandÄ±rÄ±lmasÄ± yapÄ±lÄ±r.
EÄŸitim tamamlandÄ±ktan sonra, test setindeki belgelerin doÄŸruluÄŸu hesaplanÄ±r ve ekrana yazdÄ±rÄ±lÄ±r.
Bu yÃ¶ntem, Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± yerine Scikit-learn'Ã¼n MultinomialNB sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ±n kullanÄ±lmasÄ±na olanak tanÄ±r. MultinomialNB sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ±n bir varyasyonudur 
ve Ã¶zellikle metin sÄ±nÄ±flandÄ±rma problemleri iÃ§in uygun bir seÃ§enektir.â¡
"""
MNB_classifier = SklearnClassifier(MultinomialNB())
MNB_classifier.train(training_set)
print ("MNB_classifier accuracy percent :  ",(nltk.classify.accuracy(MNB_classifier,testing_set))*100 )


# print("-----------BernoulliNB---------------------")
""" 
â¡â¢â¢â¢â€‹â€Œâ€â€ŒGaussianNB (Gaussian Naive Bayes)â€‹ sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, Bayes teoremine dayalÄ± bir olasÄ±lÄ±k modeli kullanarak sÄ±nÄ±flandÄ±rma yapar.
Bu sÄ±nÄ±flandÄ±rÄ±cÄ±, Ã¶zellik vektÃ¶rlerinin Ã¶znitelik deÄŸerlerinin normal daÄŸÄ±lÄ±m (Gaussian distribution) ile modellendiÄŸi varsayÄ±mÄ±na dayanÄ±r.
Bu varsayÄ±m altÄ±nda, sÄ±nÄ±flarÄ±n yoÄŸunluklarÄ± belirli bir Ã§izgi boyunca normal olarak daÄŸÄ±tÄ±lmÄ±ÅŸtÄ±r.
Bu sÄ±nÄ±flandÄ±rÄ±cÄ±, ğ˜€ğ—®ğ˜†Ä±ğ˜€ğ—®ğ—¹ ğ˜ƒğ—²ğ—¿ğ—¶ğ—¹ğ—²ğ—¿ğ—¶ğ—» ğ˜€Ä±ğ—»Ä±ğ—³ğ—¹ğ—®ğ—»ğ—±Ä±ğ—¿Ä±ğ—¹ğ—ºğ—®ğ˜€Ä± ğ—¶Ã§ğ—¶ğ—» ğ˜‚ğ˜†ğ—´ğ˜‚ğ—»ğ—±ğ˜‚ğ—¿.
AÅŸaÄŸÄ±daki kod bloÄŸunda, GaussianNB sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, SklearnClassifier sÄ±nÄ±fÄ± aracÄ±lÄ±ÄŸÄ±yla NLTK sÄ±nÄ±flandÄ±rma yapÄ±sÄ±na dahil edilir. ArdÄ±ndan, train yÃ¶ntemi kullanÄ±larak eÄŸitilir ve test seti Ã¼zerindeki doÄŸruluÄŸu hesaplanÄ±r.â¡
"""
# GaussianNB_classifier = SklearnClassifier(GaussianNB())
# GaussianNB_classifier.train(training_set)
# print ("GaussianNB_classifier accuracy percent :  ",(nltk.classify.accuracy(GaussianNB_classifier,testing_set))*100 )

print("----------- BernoulliNB,---------------------")
"""
â€‹â€Œâ€â€Œâ¡â¢â¢â¢BernoulliNB,â€‹ Bernoulli DaÄŸÄ±lÄ±mÄ±'nÄ± varsayan bir Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±dÄ±r.
Bu, her Ã¶zellik iÃ§in 0 veya 1 olabilecek bir Bernoulli deÄŸiÅŸkeni varsayarak Ã§alÄ±ÅŸÄ±r.
EÄŸitim verileri Ã¶zelliklerin bir varlÄ±ÄŸÄ±nÄ± veya yokluÄŸunu belirtir. 
Bu durumda, Ã¶zellik setimiz "belirli bir kelimenin varlÄ±ÄŸÄ±" veya "belirli bir kelimenin yokluÄŸu" gibi olabilir.
Bu nedenle, BernoulliNB, bir belgeye dahil edilen kelime sayÄ±sÄ±na deÄŸil,
yalnÄ±zca belgeye dahil edilen veya dahil edilmeyen kelimelerin sayÄ±sÄ±na dayanÄ±r.
BernoulliNB, Ã¶ğ˜‡ğ—²ğ—¹ğ—¹ğ—¶ğ—¸ğ—¹ğ—² ğ—¯ğ—¶ğ—¿ ğ—¯ğ—²ğ—¹ğ—´ğ—²ğ—±ğ—²ğ—¸ğ—¶ ğ—¸ğ—²ğ—¹ğ—¶ğ—ºğ—² ğ˜€ğ—®ğ˜†Ä±ğ˜€Ä± Ã§ğ—¼ğ—¸ ğ—±ğ—²ÄŸğ—¶ÅŸğ—¸ğ—²ğ—» ğ—¼ğ—¹ğ—±ğ˜‚ÄŸğ˜‚ğ—»ğ—±ğ—® ğ—¸ğ˜‚ğ—¹ğ—¹ğ—®ğ—»Ä±ÅŸğ—¹Ä±ğ—±Ä±ğ—¿.â¡

"""
BernoulliNB_classifier = SklearnClassifier(BernoulliNB())
BernoulliNB_classifier.train(training_set)
print ("BernoulliNB_classifier accuracy percent :  ",(nltk.classify.accuracy(BernoulliNB_classifier,testing_set))*100 )


# LogisticRegression, SGDClassifier
# NuSVC, SVC, LinearSVC

print("----------- LogisticRegression_classifier,---------------------")
LogisticRegression_classifier = SklearnClassifier(LogisticRegression())
LogisticRegression_classifier.train(training_set)
print ("LogisticRegression_classifier accuracy percent :  ",(nltk.classify.accuracy(LogisticRegression_classifier,testing_set))*100 )


print("----------- SGDClassifier,---------------------")
SGDClassifier_classifier = SklearnClassifier(SGDClassifier())
SGDClassifier_classifier.train(training_set)
print ("SGDClassifier accuracy percent :  ",(nltk.classify.accuracy(SGDClassifier_classifier,testing_set))*100 )


print("----------- NuSVC_classifier,---------------------")
NuSVC_classifier = SklearnClassifier(NuSVC())
NuSVC_classifier.train(training_set)
print ("NuSVC_classifier accuracy percent :  ",(nltk.classify.accuracy(NuSVC_classifier,testing_set))*100 )


# print("----------- SVC_classifier,---------------------")
# SVC_classifier = SklearnClassifier(SVC())
# SVC_classifier.train(training_set)
# print ("SVC_classifier accuracy percent :  ",(nltk.classify.accuracy(SVC_classifier,testing_set))*100 )


print("----------- LinearSVC_classifier,---------------------")
LinearSVC_classifier = SklearnClassifier(LinearSVC())
LinearSVC_classifier.train(training_set)
print ("LinearSVC_classifier accuracy percent :  ",(nltk.classify.accuracy(LinearSVC_classifier,testing_set))*100 )







"""   â¡â¢â¢â¢********************************** â€‹â€Œâ€â€ŒVoted Classifierâ€‹ *****************************â¡ """

voted_classifier = VoteClassifier(classifier,
                                  LinearSVC_classifier,
                                  NuSVC_classifier,
                                  SGDClassifier_classifier,
                                  LogisticRegression_classifier,
                                  BernoulliNB_classifier)


print ("voted_classifier accuracy percent :  ",(nltk.classify.accuracy(voted_classifier,testing_set))*100 )

# print("Classification : ", voted_classifier.classify(testing_set[0][0]),"Confidence %:", voted_classifier.confidence(testing_set[0][0])*100 )
# print("Classification : ", voted_classifier.classify(testing_set[1][0]),"Confidence %:", voted_classifier.confidence(testing_set[1][0])*100 )
# print("Classification : ", voted_classifier.classify(testing_set[2][0]),"Confidence %:", voted_classifier.confidence(testing_set[2][0])*100 )
# print("Classification : ", voted_classifier.classify(testing_set[3][0]),"Confidence %:", voted_classifier.confidence(testing_set[3][0])*100 )
# print("Classification : ", voted_classifier.classify(testing_set[4][0]),"Confidence %:", voted_classifier.confidence(testing_set[4][0])*100 )
# print("Classification : ", voted_classifier.classify(testing_set[5][0]),"Confidence %:", voted_classifier.confidence(testing_set[5][0])*100 )